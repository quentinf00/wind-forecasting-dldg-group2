# -*- coding: utf-8 -*-
"""Copie de DLDGWindforecastingEdouardQuentin.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p7tFu2WsOb0ew2E9uO0svn3X63wA4B9_
"""

from pathlib import Path
import pandas as pd
import xarray as xr
import torch
from functools import lru_cache
import torch.utils.data as td
import numpy as np 
import matplotlib.pyplot as plt

folder = '/homes/q20febvr/local/dldg/windforecast'
hr_path = Path(folder) / 'high_res_data'
mr_path = Path(folder) / 'med_res_data'
lr_path = Path(folder) / 'low_res_data'
out_path = Path(folder) / 'output_data'



class WindForecastDataset(td.Dataset):                                                                              
    def __init__(                                                                                                   
        self,                                                                                                       
        period,                                                                                                     
        hr_path='high_res_data',                                                                                    
        mr_path='med_res_data',                                                                                          
        lr_path='low_res_data',                                                                                          
        out_path='output_data'                                                                                      
    ):                                                                                                              
                                                                                                                    
                                                                                                                    
        self.ds_hr = xr.open_zarr(hr_path)                                                                  
        self.ds_mr = xr.open_zarr(mr_path)                                                                   
        self.ds_lr = xr.open_zarr(lr_path)                                                                   
        self.ds_out = xr.open_zarr(out_path)       
        valid_dates =   (
            self.ds_out.assign(date=lambda ds: ds.valid_time.dt.date.compute())
            .groupby('date')
            .apply(lambda g: np.all(~np.isnan(g.du)))
            .pipe(lambda ds: ds.isel(date=ds))
            .pipe(lambda ds: pd.to_datetime(ds.date.values))
        )                                                     
                                                                                                                    
        self.date_items = sorted(list(set(pd.to_datetime(self.ds_hr.training_item.values, unit='D')) & set(period) & set(valid_dates)))
        self.ds_out
        print(f'{len(self.date_items)} dates available out of {len(period)} dates asked')                           
                                                                                                                    
    def __len__(self):                                                                                              
        return len(self.date_items)                                                                                 

    def check_dim(self, ds):
      if ds.dims.get('training_item', 0) > 1:
        return ds.isel(training_item=0)
      return ds

    def fix_na_mr(self, ds):
      mr_grid = {'g_lat': np.arange(43, 45, 0.05), 'g_lon': np.arange(4, 7.55, 0.05)}

      return (
          ds
            .sel(mr_grid, method='nearest')
            .interpolate_na('g_lat')
            .interpolate_na('g_lon')
      )


    def fix_na_lr(self, ds):
      lr_grid = {'g_lat': np.arange(43, 45, 0.1), 'g_lon': np.arange(4, 7.6, 0.1)}

      return (
          ds
            .sel(lr_grid, method='nearest')
            .interpolate_na('g_lat')
            .interpolate_na('g_lon')
      )

    def __getitem__(self, item):                                                                                    
        date = self.date_items[item]                                                                                
        hr_item = self.ds_hr.sel(training_item=date).pipe(self.check_dim)[['u10', 'v10', 'du', 'dv']].compute().to_array().data.astype('float32')        
        mr_item = self.ds_mr.sel(training_item=date).pipe(self.check_dim)[['u10', 'v10', 'du', 'dv']].pipe(self.fix_na_mr).compute().to_array().data.astype('float32')
        lr_item = self.ds_lr.sel(training_item=date).pipe(self.check_dim)[['u10', 'v10', 'du', 'dv']].pipe(self.fix_na_lr).compute().to_array().data.astype('float32')
        out_item = self.ds_out.sel(dt=str(date.date()))[['du', 'dv']].compute().to_array().data.astype('float32')
        ret_values = (hr_item, mr_item, lr_item, out_item)
        #print(item, date)
        #for r in ret_values:
          #print(r.shape)                                                                                   
        return ret_values


test_period = pd.to_datetime('2018-01-01'), pd.to_datetime('2018-12-31') 
train_period = pd.to_datetime('2016-01-01'), test_period[0]                       
                                                                                           

train_ds, val_ds = td.random_split(
    WindForecastDataset(
      pd.to_datetime(pd.date_range(*train_period)),
      hr_path=hr_path,                                                                                    
      mr_path=mr_path,                                                                                          
      lr_path=lr_path,                                                                                          
      out_path=out_path,   
  ),
  [498, 100], generator=torch.Generator().manual_seed(42))

test_ds = WindForecastDataset(
    pd.to_datetime(pd.date_range(*test_period)),
    hr_path=hr_path,                                                                                    
    mr_path=mr_path,                                                                                          
    lr_path=lr_path,                                                                                          
    out_path=out_path, 
  )
                                                                                                                     

bs = 32
train_dl = td.DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=16)
val_dl = td.DataLoader(val_ds, batch_size=bs, shuffle=False, num_workers=16)
test_dl = td.DataLoader(test_ds, batch_size=bs, shuffle=False, num_workers=16)


import einops
import torch
import pytorch_lightning as pl
import torch.nn.functional as F

class WindForecastCNN(torch.nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1 = torch.nn.Conv3d(
        in_channels=4,
        out_channels=16,
        kernel_size=(3, 3, 3),
      )
    self.relu = torch.nn.ReLU()
    self.conv_out = torch.nn.Conv3d(
        in_channels=16,
        out_channels=120,
        kernel_size=(3, 3, 3),
      )

  def forward(self,x):
    x = self.conv1(x)
    x = self.relu(x)
    x = self.conv_out(x)
    x = einops.reduce(
        x,
        'bs (out_ch t_out) t_in lon_in lat_in -> bs out_ch t_out',
        'mean',
        out_ch=2,
        t_out=60
    )
    return x


class WindForecastDCNN(torch.nn.Module):
  def __init__(self):
    super().__init__()
    self.conv_in = torch.nn.Conv3d(
        in_channels=4,
        out_channels=16,
        kernel_size=(3, 3, 3),
      )
    self.relu = torch.nn.ReLU()

    layers = []
    for _ in range(3):
        layers.extend([
            torch.nn.Conv3d(
                in_channels=16,
                out_channels=16,
                kernel_size=(3, 3, 3),
            ),
            torch.nn.BatchNorm3d(
                num_features=16,
            ),
            torch.nn.ReLU()
        ])

    self.nn = torch.nn.Sequential(*layers)
    self.conv_out = torch.nn.Conv3d(
        in_channels=16,
        out_channels=120,
        kernel_size=(3, 3, 3),
      )

  def forward(self,x):
    x = self.conv_in(x)
    x = self.nn(x)
    x = self.conv_out(x)
    x = einops.reduce(
        x,
        'bs (out_ch t_out) t_in lon_in lat_in -> bs out_ch t_out',
        'mean',
        out_ch=2,
        t_out=60
    )
    return x


class WindForecastSCNN(torch.nn.Module):
  def __init__(self):
    super().__init__()
    self.conv_in = torch.nn.Conv3d(
        in_channels=4,
        out_channels=16,
        kernel_size=(3, 3, 3),
      )
    self.relu = torch.nn.ReLU()

    layers = []
    for _ in range(3):
        layers.extend([
            torch.nn.Conv3d(
                in_channels=16,
                out_channels=16,
                kernel_size=(3, 3, 3),
            ),
            torch.nn.BatchNorm3d(
                num_features=16,
            ),
            torch.nn.ReLU()
        ])

    self.nn = torch.nn.Sequential(*layers)

    self.conv_out = torch.nn.Conv3d(
        in_channels=16,
        out_channels=32,
        kernel_size=(3, 3, 3),
      )

    self.linear = torch.nn.Linear(32, 120)

  def forward(self,x):
    x = self.conv_in(x)
    x = self.nn(x)
    x = self.conv_out(x)
    x = einops.reduce(
        x,
        'bs in_c t_in lon_in lat_in -> bs in_c',
        'mean',
    )
    x = self.linear(x)
    x = einops.rearrange(
        x,
        'bs (out_c out_t) -> bs out_c out_t',
        out_c=2,
        out_t=60,
    )
    return x


class TrainWindForecast(pl.LightningModule):
    def __init__(self, model_cls=WindForecastCNN):
      super().__init__()
      self.model_hr = model_cls()
      self.model_mr = model_cls()
      self.model_lr = model_cls()
      self.w_hr = torch.nn.Parameter(torch.ones(1,1,60))
      self.w_mr = torch.nn.Parameter(torch.ones(1,1,60))
      self.w_lr = torch.nn.Parameter(torch.ones(1,1,60))


      self.test_dates = None
      self.test_figs = {}
      self.y_pred_all = None
      self.y_true_all = None
      self.test_xrds = None
  
    def forward(self,x_hr,x_mr,x_lr):
      y_hr = self.model_hr(x_hr)
      return y_hr
      # y_mr = self.model_mr(x_mr)
      # y_lr = self.model_lr(x_lr)

      # return (self.w_hr * y_hr + self.w_mr * y_mr + self.w_lr * y_lr) / (self.w_hr+self.w_mr+ self.w_lr)

    def training_step(self, batch, batch_idx):
      x_hr, x_mr, x_lr, y = batch
      y_pred = self(x_hr,x_mr,x_lr)
      loss = F.mse_loss(y_pred, y)
      # Logging to TensorBoard by default
      self.log("train_loss", loss)
      return loss

    def validation_step(self, batch, batch_idx):
      x_hr, x_mr, x_lr, y = batch
      y_pred = self(x_hr,x_mr,x_lr)
      loss = F.mse_loss(y_pred,y)
      # Logging to TensorBoard by default
      self.log("validation_loss", loss)
      return loss


    def on_test_epoch_start(self):
      self.test_dates = self.trainer.test_dataloaders[0].dataset.date_items

    def test_step(self, batch, batch_idx):
      x_hr, x_mr, x_lr, y = batch
      y_pred = self(x_hr,x_mr,x_lr)

      loss = F.mse_loss(y_pred,y)
      self.log("test_loss", loss)
      return y_pred.cpu().numpy(), y.cpu().numpy() 

    def test_epoch_end(self, test_outputs):
      self.y_pred_all = np.concatenate([it[0] for it in test_outputs])
      self.y_true_all = np.concatenate([it[1] for it in test_outputs])

      self.test_xrds = xr.Dataset(
          {
              'y_true': (('date', 'var', 'time'), self.y_true_all),
              'y_pred': (('date', 'var', 'time'), self.y_pred_all),
          },
          coords={
              'date':  (('date',), self.test_dates),
              'var': (('var',), ['du', 'dv']),
              'time': (('time',), np.arange(0, 6*60, 6)),
          }
      )

      amp_error = (
          self.test_xrds
          .assign(pred_err=lambda ds: ds.y_true - ds.y_pred)
          [['y_true', 'pred_err']]
          .pipe(
              lambda ds: ds.sel(var='du')**2 + ds.sel(var='dv')**2
          ).pipe(np.sqrt)
      )
    
      fig, ax = plt.subplots()
      amp_error.mean('time').y_true.plot(ax=ax)
      amp_error.mean('time').pred_err.plot(ax=ax)
      ax.legend(['AROME', 'ours'])
      self.test_figs['amp err'] = fig
      self.logger.experiment.add_figure('amplitude err ts', fig, global_step=self.current_epoch)

      fig, ax = plt.subplots()
      amp_error.mean('date').y_true.plot(ax=ax)
      amp_error.mean('date').pred_err.plot(ax=ax)
      ax.legend(['AROME', 'ours'])
      self.test_figs['win_err'] = fig
      self.logger.experiment.add_figure('amplitude err win', fig, global_step=self.current_epoch)


      fig, ax = plt.subplots()
      ax.plot(self.w_hr.detach().cpu().numpy().squeeze())
      ax.plot(self.w_mr.detach().cpu().numpy().squeeze())
      ax.plot(self.w_lr.detach().cpu().numpy().squeeze())
      ax.legend(['weight high res', 'weight medium res', 'weight low res'])
      self.test_figs['weights'] = fig
      self.logger.experiment.add_figure('weights model', fig, global_step=self.current_epoch)
      # % improvement
      percent_improvement = (
          self.test_xrds
          .assign(pred_err=lambda ds: ds.y_true - ds.y_pred)
          .pipe(np.abs)
          .mean(['time', 'var'])
          .assign(ratio=lambda ds: ds.pred_err / ds.y_true)
      )

      mean_improv = percent_improvement.ratio.mean().item()
      worst_improv = percent_improvement.ratio.max().item()
      best_improv = percent_improvement.ratio.min().item()
      self.log('mean_improvement', mean_improv)
      self.log('worst_improv', worst_improv)
      self.log('best_improv', best_improv)

      fig, ax = plt.subplots()
      percent_improvement.ratio.plot(ax=ax)
      self.test_figs['ratio_ts'] = fig
      self.logger.experiment.add_figure('Ratio TS', fig, global_step=self.current_epoch)


    def configure_optimizers(self):

        opt = torch.optim.Adam(self.parameters(), lr=1e-3)
        return {
            'optimizer': opt,
            'lr_scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(
                opt, verbose=True, patience=50, min_lr=10 ** -5
            ),
            'monitor': 'validation_loss'
        }

model_checkpoint = pl.callbacks.ModelCheckpoint(monitor='validation_loss', verbose=True)

trainer = pl.Trainer(gpus=1, max_epochs=400, callbacks=[model_checkpoint], log_every_n_steps=2)
"""
version_6
"""
lit_mod = TrainWindForecast(model_cls=WindForecastCNN)

"""
version_8
"""
# lit_mod = TrainWindForecast(model_cls=WindForecastDCNN)


"""
version_10
"""
# lit_mod = TrainWindForecast(model_cls=WindForecastSCNN)

ckpt_path=None
trainer.fit(lit_mod, train_dl,val_dataloaders=val_dl)

# trainer = pl.Trainer(gpus=[0], max_epochs=400, callbacks=[model_checkpoint])
trainer.test(lit_mod, test_dataloaders=test_dl)

"""
lit_mod = TrainWindForecast(model_cls=WindForecastCNN).load_from_checkpoint(ckpt_path)
trainer.test(lit_mod, test_dataloaders=test_dl)



ckpt_path = 'lightning_logs/version_10/checkpoints/epoch=33-step=2141.ckpt'
ckpt = torch.load(ckpt_path)
lit_mod = TrainWindForecast(model_cls=WindForecastSCNN)
lit_mod.load_state_dict(ckpt['state_dict'])
trainer = pl.Trainer(gpus=[1], max_epochs=100)
trainer.test(lit_mod, test_dataloaders=test_dl)
"""
